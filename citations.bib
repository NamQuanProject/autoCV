@article{TRAN2025104321,
title = {SHREC GS-3DORC: Towards the advancements of 3D Gaussian Splatting object part retrieval},
journal = {Computers & Graphics},
volume = {132},
pages = {104321},
year = {2025},
issn = {0097-8493},
doi = {https://doi.org/10.1016/j.cag.2025.104321},
url = {https://www.sciencedirect.com/science/article/pii/S0097849325001621},
author = {Thien-Phuc Tran and Minh-Quang Nguyen and Thanh-Khoi Nguyen and Nam-Quan Nguyen and Tam V. Nguyen and Minh-Triet Tran},
keywords = {Gaussian Splatting, 3D object segmentation, 3D object retrieval, 3D object part understanding},
abstract = {Part-level understanding is crucial for advancing compositional reasoning in 3D vision tasks such as robotics, modular design, and neural rendering. Existing 3D retrieval benchmarks typically focus on whole-object retrieval, overlooking the challenge of identifying meaningful subcomponents, especially under emerging neural representations like 3D Gaussian Splatting (3DGS). We introduce GS-3DORC, the first benchmark dedicated to object part retrieval from multi-view 3DGS inputs to address this gap. Participants are tasked with decomposing full 3DGS objects, each composed of 2–50 parts, and retrieving corresponding segments from a database of 7705 pre-segmented parts spanning 107 categories. The benchmark introduces challenges in part-level geometric reasoning, matching robustness, and scale-awareness. Three teams submitted 14 runs, with the top method achieving mean Average Precision (mAP) of 0.379. While the results demonstrate promising capabilities in neural part retrieval, they also reveal significant room for improvement. We release this benchmark to foster research in part-aware 3D learning and bridge the gap between generative representations and practical retrieval applications.}
}

@inproceedings{MV25-MV200-54,
    author    = {Nam-Quan Nguyen and Tran-Uy Huynh and Gia-Han Nguyen-Hoang and Minh-Triet Tran and Trong-Le Do},
    title     = {LH-MemUDA: Low-High Resolution Memory Black-box Unsupervised Domain Adaptation},
    booktitle = {Proceedings of the Eighteenth International Conference on Machine Vision (ICMV 2025) 2025},   
    year      = {2025}
}




@inproceedings{10.1145/3746027.3762090,
author = {Nguyen, Nam-Quan and Le, Minh-Hoang and Vong, Vinh-Toan and Tran, Minh-Triet},
title = {ENRIC: EveNt-AwaRe Captioning with Image Retrieval via UnCertainty-Guided Re-ranking and Semantic Ensemble Reasoning},
year = {2025},
isbn = {9798400720352},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3746027.3762090},
doi = {10.1145/3746027.3762090},
abstract = {In many real-world applications, labeling an image ''a man riding a horse'' fails to satisfy demands for the who, when, where, and why. Although LVLMs excel at describing visual content, isolated images often lack the event context; users thus rely on related news articles or social posts to enrich them, but cropping or resizing complicates tracking back to their source. In this paper, we propose ENRIC, an innovative end-to-end system for the EVENTA Challenge Track 1, leveraging the OpenEvents-V1 dataset, comprising over 200,000 news articles paired with more than 400,000 images. Our system includes three components: (1) semantic retrieval filters candidate article images via vision-language embeddings, (2) uncertainty-guided re-ranking flags ambiguous queries using three confidence heuristics and re-ranks candidates by combining visual similarity with texture similarity, and (3) event-aware caption generation employs chain-of-thought prompting that aggregates five inputs from article, image, and CIDEr-derived contexts to guide the LLM in incorporating all necessary elements. ENRIC achieved the highest combined evaluation score of 0.5501, ranking first and outperforming other solutions across nearly all metrics. By combining semantic retrieval, uncertainty-guided re-ranking, and event-aware caption generation, ENRIC demonstrates the efficiency of its approach for event-enriched image analysis. GitHub repository: https://github.com/NamQuanProject/EVENTA25-ENRIC},
booktitle = {Proceedings of the 33rd ACM International Conference on Multimedia},
pages = {14250–14256},
numpages = {7},
keywords = {event-aware captioning, image retrieval, re-ranking},
location = {Dublin, Ireland},
series = {MM '25}
}
